import os, re, json
from dotenv import load_dotenv
from agents.pdf_rag import query_pdf_knowledge   # ğŸ”¥ PDF RAG ì—°ê²°

# OpenAI SDK
use_llm = False
client = None
MODEL = "gpt-4o-mini"

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if OPENAI_API_KEY:
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
        use_llm = True
    except Exception:
        use_llm = False


class NewsAnalystAgent:
    def __init__(self, model=MODEL):
        self.model = model

    def analyze(self, article):
        """
        ì…ë ¥: {title, summary, link, published, source}
        ì¶œë ¥: {"headline","summary","impact","keywords","rag_context"}
        """
        if not use_llm:
            return {
                "headline": article["title"],
                "summary": (article["summary"] or "ê¸°ì‚¬ ë³¸ë¬¸ ì—†ìŒ")[:200],
                "impact": "LLM ë¹„í™œì„±í™” ìƒíƒœ (ì˜í–¥ ë¶„ì„ ìƒëµ)",
                "keywords": [],
                "rag_context": []
            }

        prompt = f"""
ì—­í• : ê²½ì œ/ì¦ì‹œ ì „ë¬¸ ê¸°ì
ê¸°ì‚¬ ì œëª©: {article['title']}
ê¸°ì‚¬ ìš”ì•½(ì›ë¬¸ ì œê³µ): {article['summary']}

ìš”ì²­:
1) í•œì¤„ í•µì‹¬ ìš”ì•½ (<=20ì, í•œêµ­ì–´)
2) ê¸°ì‚¬ í•µì‹¬ ë‚´ìš© ìš”ì•½ (3ë¬¸ì¥ ì´ë‚´)
3) ì˜í–¥ ë¶„ì„: ê±°ì‹œ/ì‚°ì—…/ì¢…ëª©ì— ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ì˜í–¥ì„ ì¤„ì§€
4) í‚¤ì›Œë“œ 3ê°œ (ì˜ë¬¸ ì•½ì–´ ê°€ëŠ¥)

ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ:
{{"headline":"","summary":"","impact":"","keywords":["","",""]}}
"""

        try:
            resp = client.chat.completions.create(
                model=self.model,
                temperature=0.2,
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ê²½ì œ ë‰´ìŠ¤ë¥¼ ì˜ ìš”ì•½í•˜ëŠ” ë¶„ì„ê°€ì•¼. JSONë§Œ ì¶œë ¥í•´."},
                    {"role": "user", "content": prompt}
                ]
            )
            content = resp.choices[0].message.content.strip()
            m = re.search(r"\{.*\}", content, re.S)
            data = json.loads(m.group(0)) if m else {}

            # ğŸ”¥ PDF RAG ì§€ì‹ ë³´ê°•
            rag_context = []
            for kw in data.get("keywords", []):
                if kw:
                    docs = query_pdf_knowledge(kw, n_results=1)
                    if docs:
                        rag_context.append(f"{kw}: {docs[0]}")

            data["rag_context"] = rag_context
            return data

        except Exception as e:
            return {
                "headline": article["title"],
                "summary": (article["summary"] or "ê¸°ì‚¬ ë³¸ë¬¸ ì—†ìŒ")[:200],
                "impact": f"ë¶„ì„ ì‹¤íŒ¨: {e}",
                "keywords": [],
                "rag_context": []
            }


# === ì§ì ‘ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸) ===
if __name__ == "__main__":
    from agents.news_crawler import NewsCrawlerAgent
    from agents.news_ranker import NewsRankerAgent

    crawler = NewsCrawlerAgent()
    articles = crawler.collect_items()
    print(f"ì´ {len(articles)}ê°œ ê¸°ì‚¬ í¬ë¡¤ë§ë¨")

    ranker = NewsRankerAgent(topk=3)
    ranked = ranker.rank_items(articles)

    analyst = NewsAnalystAgent()
    for score, art in ranked:
        result = analyst.analyze(art)
        print("\n----")
        print("ì œëª©:", result["headline"])
        print("ìš”ì•½:", result["summary"])
        print("ì˜í–¥:", result["impact"])
        print("í‚¤ì›Œë“œ:", ", ".join(result["keywords"]))
        if result["rag_context"]:
            print("ğŸ“š ì¶”ê°€ ì§€ì‹:")
            for ctx in result["rag_context"]:
                print("-", ctx)
